# -*- coding: utf-8 -*-
"""Copy of concrete_preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l3POqI3_emuU6Vn_9WqY9NyGAgXCuyqn
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

#df = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/Comp ML/Assessment-1/Concrete Regression/Concrete_Data.xls')
#df.columns = ['Cement', 'Blast Furnace Slag', 'Fly Ash', 'Water', 'Superplasticizer', 'Coarse Aggregate', 'Fine Aggregate', 'Age', 'Concrete Compressive Strength']
#df.to_csv('/content/drive/MyDrive/Colab Notebooks/Comp ML/Assessment-1/Concrete Regression/Concrete_Data.csv', index=False)

df = pd.read_csv('https://raw.githubusercontent.com/ppxcd1-20462957/COMP3009-Machine-Learning-Assignment-1/master/Concrete_Data.csv?token=GHSAT0AAAAAAB2LY5YRKTBX3BVZFDCVKKQ6Y3RNIAQ')
df.head()

corrMatt = df.corr()
# Generate a mask for the upper triangle
mask = np.zeros_like(corrMatt)
mask[np.triu_indices_from(mask)] = True
# Set up the matplotlib figure
fig, ax = plt.subplots(figsize=(20, 12))
plt.title('Concrete Feature Correlation')
# Generate a custom diverging colormap
cmap = sns.diverging_palette(260, 10, as_cmap=True)
# Draw the heatmap with the mask and correct aspect ratio
sns.heatmap(corrMatt, vmax=1.2, square=False, cmap=cmap, mask=mask, ax=ax, annot=True, fmt='.2g', linewidths=1);

"""##Outliers"""

data_mean = df.iloc[:, :]
data_mean.plot(kind='box', subplots=True, layout=(8,4), sharex=False, sharey=False, fontsize=12, figsize=(15,20));

"""##to check need for normalisation"""

fig,ax=plt.subplots(1,figsize=(20,8))
sns.boxplot(data=df.iloc[:, :],ax=ax)

X = df.drop('Concrete Compressive Strength', axis=1)
Y = df['Concrete Compressive Strength']

cols = list(X.columns.values)
from sklearn.preprocessing import MinMaxScaler
min_max_scaler = MinMaxScaler()
X[cols] = min_max_scaler.fit_transform(X[cols])

X.head()

from sklearn.model_selection import train_test_split
train_X , test_X , train_Y ,test_Y = train_test_split(X,Y, test_size=0.20)
print(train_Y.shape)
print(train_X.shape)

from sklearn.svm import SVR
from sklearn.model_selection import cross_val_score
svm_r = SVR(C=1.0, kernel='poly',degree=7,gamma='scale')
svm_r.fit(train_X, train_Y)
svm_r_score = svm_r.score(test_X, test_Y) #R2 score
print('The SVM accuracy score is {:03.2f}'.format(svm_r_score))
pred_Y = svm_r.predict(test_X)
cross_valSVM = np.average(cross_val_score(svm_r,train_X, np.ravel(train_Y),scoring='neg_mean_squared_error', cv=10))
print("Cross validation score:", cross_valSVM)
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(test_Y, pred_Y)
print("MSE:", mse)

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score
linear = LinearRegression().fit(train_X, train_Y)
linear_score = linear.score(test_X, test_Y) #R2 score
print('The Linear regression accuracy score is {:03.2f}'.format(linear_score))
cross_val_linear = np.average(cross_val_score(linear,train_X,train_Y,scoring='neg_mean_squared_error', cv=10))
print("Cross validation score:", cross_val_linear)
pred_Y = linear.predict(test_X)
mse = mean_squared_error(test_Y, pred_Y)
print("MSE:", mse)